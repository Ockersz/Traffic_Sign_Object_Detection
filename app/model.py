# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1itPaAF7gZUMiGcjCpVNszr4NnvI8xOih
"""

!cp '/content/drive/MyDrive/data.zip' '/content/'

!unzip 'data.zip'

import os
import cv2
import numpy as np
from tensorflow.keras import layers, models

def load_data(data_dir, num_coordinates=4):
    images = []
    labels = []

    for image_file in os.listdir(os.path.join(data_dir, 'images')):
        img_path = os.path.join(data_dir, 'images', image_file)
        img = cv2.imread(img_path)
        img = cv2.resize(img, (224, 224))  # Adjust size as needed
        images.append(img)

        label_path = os.path.join(data_dir, 'labels', image_file.replace('.jpg', '.txt'))
        with open(label_path, 'r') as file:
            label_str = file.read().strip().split()
            label = list(map(float, label_str[1:]))[:num_coordinates]  # Exclude the class and limit coordinates
            labels.append(label + [0.0] * (num_coordinates - len(label)))  # Pad with zeros if needed

    return np.array(images), np.array(labels)

train_images, train_labels = load_data('3/train')
train_labels = np.array(train_labels)  # Convert labels to NumPy array

# Now you can use model.fit without any issues
model.fit(train_images, train_labels, epochs=10, batch_size=32)

# Assuming you already have the model and the training data loaded

def load_validation_data(data_dir, num_coordinates=4):
    images = []
    labels = []

    for image_file in os.listdir(os.path.join(data_dir, 'images')):
        img_path = os.path.join(data_dir, 'images', image_file)
        img = cv2.imread(img_path)
        img = cv2.resize(img, (224, 224))  # Adjust size as needed
        images.append(img)

        label_path = os.path.join(data_dir, 'labels', image_file.replace('.jpg', '.txt'))
        with open(label_path, 'r') as file:
            label_str = file.read().strip().split()
            label = list(map(float, label_str[1:]))[:num_coordinates]  # Exclude the class and limit coordinates
            labels.append(label + [0.0] * (num_coordinates - len(label)))  # Pad with zeros if needed

    return np.array(images), np.array(labels)

valid_images, valid_labels = load_validation_data('3/valid')
valid_labels = np.array(valid_labels)  # Convert labels to NumPy array

# Now you can use model.evaluate to evaluate the performance on the validation set
validation_loss = model.evaluate(valid_images, valid_labels, batch_size=32)

print(f'Validation Loss: {validation_loss}')

# Assuming you already have the model and the training/validation data loaded

def load_test_data(data_dir, num_coordinates=4):
    images = []
    labels = []

    for image_file in os.listdir(os.path.join(data_dir, 'images')):
        img_path = os.path.join(data_dir, 'images', image_file)
        img = cv2.imread(img_path)
        img = cv2.resize(img, (224, 224))  # Adjust size as needed
        images.append(img)

        label_path = os.path.join(data_dir, 'labels', image_file.replace('.jpg', '.txt'))
        with open(label_path, 'r') as file:
            label_str = file.read().strip().split()
            label = list(map(float, label_str[1:]))[:num_coordinates]  # Exclude the class and limit coordinates
            labels.append(label + [0.0] * (num_coordinates - len(label)))  # Pad with zeros if needed

    return np.array(images), np.array(labels)

test_images, test_labels = load_test_data('3/test')
test_labels = np.array(test_labels)  # Convert labels to NumPy array

# Now you can use model.evaluate to evaluate the performance on the test set
test_loss = model.evaluate(test_images, test_labels, batch_size=32)

print(f'Test Loss: {test_loss}')

import cv2
import numpy as np

# Assuming you already have the trained model

# Load and preprocess a single image
def load_and_preprocess_image(image_path):
    img = cv2.imread(image_path)
    img = cv2.resize(img, (224, 224))  # Adjust size as needed
    img = np.expand_dims(img, axis=0)  # Add batch dimension
    return img

# Path to the image you want to test
image_path = '/content/3/test/images/00000_00000_00017_png.rf.6c2381a6a103a041f23159fbd44868ed.jpg'

# Load and preprocess the image
input_image = load_and_preprocess_image(image_path)

# Use the model to make predictions
predictions = model.predict(input_image)

# Interpret the model's output
# In this example, assuming the model outputs (x, y, width, height) coordinates
x, y, width, height = predictions[0]

# Now you can use these coordinates as needed
print(f'Predicted coordinates: (x={x}, y={y}, width={width}, height={height})')

import cv2
import numpy as np

# Assuming you have the trained model and test data loaded

def calculate_iou(box1, box2):
    """
    Calculate IoU (Intersection over Union) for two bounding boxes.
    """
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[0] + box1[2], box2[0] + box2[2])
    y2 = min(box1[1] + box1[3], box2[1] + box2[3])

    intersection = max(0, x2 - x1) * max(0, y2 - y1)
    area_box1 = box1[2] * box1[3]
    area_box2 = box2[2] * box2[3]
    union = area_box1 + area_box2 - intersection

    iou = intersection / union if union > 0 else 0.0
    return iou

# Assuming test_images and test_labels are already loaded

# Use the model to make predictions
predictions = model.predict(test_images)

# Interpret the model's output and compute IoU for each prediction
iou_values = []
for i in range(len(predictions)):
    predicted_box = predictions[i][:4]  # Assuming the model outputs (x, y, width, height) coordinates
    true_box = test_labels[i][:4]

    iou = calculate_iou(predicted_box, true_box)
    iou_values.append(iou)

# Calculate Mean IoU
mean_iou = np.mean(iou_values)

print(f'Mean IoU: {mean_iou}')
# Assuming you have the Mean IoU value calculated

# Convert Mean IoU to percentage
accuracy_percentage = mean_iou * 100

print(f'Accuracy: {accuracy_percentage:.2f}%')